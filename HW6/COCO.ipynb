{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is borrow from HW4_spring2025.pdf, my code will be follow by a comment\n",
    "from PIL import Image\n",
    "import os\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "# Set COCO dataset paths\n",
    "data_dir = os.getcwd()\n",
    "#  mac users\n",
    "# ann_file = os.path.join(data_dir, \"annotations/instances_train2014.json\") \n",
    "# image_dir = os.path.join(data_dir, \"train2014/train2014\")  \n",
    "\n",
    "# windows users\n",
    "ann_file = os.path.join(data_dir, r\"annotations\\instances_train2014.json\") \n",
    "image_dir = os.path.join(data_dir, r\"train2014\\train2014\")  \n",
    "\n",
    "\n",
    "output_dir = \"output_datasets\"\n",
    "\n",
    "# Load COCO dataset\n",
    "coco = COCO(ann_file)\n",
    "\n",
    "# Ensure output directories exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def save_image(img_info, category_name, dataset_type, split):\n",
    "    \"\"\"Saves the extracted image into a structured output directory for training/validation.\"\"\"\n",
    "    img_path = os.path.join(image_dir, img_info['file_name'])\n",
    "    save_dir = os.path.join(output_dir, dataset_type, split, category_name)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # # Check if the file exists before opening\n",
    "    # if not os.path.exists(img_path):\n",
    "    #     print(f\"Skipping {img_info['file_name']} - File not found.\")\n",
    "    #     return  \n",
    "\n",
    "    # Load and resize image\n",
    "    img = Image.open(img_path).resize((64, 64))\n",
    "    img.save(os.path.join(save_dir, img_info['file_name']))\n",
    "\n",
    "def extract_images(cat_names, min_instances=1, max_instances=1, multiple_categories=False, dataset_type=\"single_instance\"):\n",
    "    \"\"\"\n",
    "    Extracts images based on object count conditions for single-instance or multi-instance datasets.\n",
    "    - min_instances: Minimum number of object instances required.\n",
    "    - max_instances: Maximum number of object instances allowed.\n",
    "    - multiple_categories: If True, selects images with multiple different object types.\n",
    "    \"\"\"\n",
    "    cat_ids = coco.getCatIds(catNms=cat_names)\n",
    "    img_ids = coco.getImgIds(catIds=cat_ids)\n",
    "    # Counter for extracted images\n",
    "    extracted = 0  \n",
    "\n",
    "    \n",
    "    images_to_process = [] # List to store valid images\n",
    "    target_classes = [\"cup\", \"car\", \"cat\", \"dog\", \"chair\"] # remeber classes we are interested in, with single categories, we need to make sure that other categories are not present\n",
    "    current_category = cat_names[0] ## e.g. current_category: person\n",
    "    other_categories = [cat for cat in target_classes if cat != current_category] ## e.g. other_categories: ['book', 'bottle', 'cup', 'chair']\n",
    "\n",
    "\n",
    "    # loop through the images\n",
    "    for img_id in img_ids:\n",
    "        img_info = coco.loadImgs(img_id)[0]\n",
    "        # These are annotation IDs for objects detected in a specific image. (we are not using this)\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id, iscrowd=False)\n",
    "        # anns includes bounding box, category ID, and segmentation, area, imageID.\n",
    "        anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "\n",
    "        # Count objects per category\n",
    "        obj_counts = {}\n",
    "\n",
    "        obj_categories = set() # set to store object categories in the image. e.g. {'person', 'chair'}\n",
    "        \n",
    "        # max_area_category = None # variable to store the category with the maximum area\n",
    "        # max_area = 0\n",
    "\n",
    "        for ann in anns:\n",
    "\n",
    "            # return object category name, like obj_category: umbrella, obj_category: carrot...\n",
    "            obj_category = coco.loadCats(ann['category_id'])[0]['name']\n",
    "\n",
    "            # obj count for each category, like obj_counts: {'umbrella': 1}, obj_counts: {'carrot': 3}...\n",
    "            obj_counts[obj_category] = obj_counts.get(obj_category, 0) + 1\n",
    "            \n",
    "            obj_categories.add(obj_category) # keep track of all object categories in the image\n",
    "\n",
    "        #     if ann['area'] > max_area: # Track category with largest area\n",
    "        #         max_area = ann['area']\n",
    "        #         max_area_category = obj_category\n",
    "\n",
    "        # if max_area_category != current_category: # Skip images with largest area not being the target category\n",
    "        #     continue\n",
    "        \n",
    "        if dataset_type in [\"single_instance\", \"multi_instance_same\"]: # Skip images with other unwanted categories for single-instance and multi-instance same\"\n",
    "            if any(other_cat in obj_categories for other_cat in other_categories):\n",
    "                continue\n",
    "\n",
    "        if multiple_categories:\n",
    "            # Ensure multiple object categories are present(modified)\n",
    "            if len(obj_counts) >= 2 and current_category in obj_counts and any(other_cat in obj_counts for other_cat in other_categories): # modified this line to include other_categories\n",
    "                images_to_process.append(img_info) # instead of saving the image, I append the image info to the list\n",
    "                extracted += 1\n",
    "        elif dataset_type == \"multi_instance_same\":\n",
    "            # Ensure multiple instances of the same object category\n",
    "            if cat_names[0] in obj_counts and obj_counts[cat_names[0]] >= min_instances:\n",
    "                images_to_process.append(img_info) # instead of saving the image, I append the image info to the list\n",
    "                extracted += 1\n",
    "        else:\n",
    "            # Ensure the number of instances falls within the desired range for single-instance\n",
    "            if all(obj in obj_counts for obj in cat_names) and min_instances <= obj_counts[cat_names[0]] <= max_instances:\n",
    "                images_to_process.append(img_info) # instead of saving the image, I append the image info to the list\n",
    "                extracted += 1\n",
    "\n",
    "        # Limit to 500 images per dataset for testing \n",
    "        if extracted >= 2000:  \n",
    "            break\n",
    "        \n",
    "    train_images = images_to_process[:1500] # Split the images into training and validation sets (1500 training, 500 validation)\n",
    "    val_images = images_to_process[1500:2000] # Split the images into training and validation sets (1500 training, 500 validation)\n",
    "\n",
    "    for img_info in train_images:   # Save training and validation images\n",
    "        save_image(img_info, cat_names[0], dataset_type, 'train')\n",
    "\n",
    "    for img_info in val_images:   # Save training and validation images\n",
    "        save_image(img_info, cat_names[0], dataset_type, 'val')\n",
    "\n",
    "# Extract Single-instance Dataset\n",
    "# not enough images for the following requirements\n",
    "# extract_images([\"cup\"], min_instances=1, max_instances=1, dataset_type=\"single_instance\")\n",
    "# extract_images([\"car\"], min_instances=1, max_instances=1, dataset_type=\"single_instance\")\n",
    "# extract_images([\"cat\"], min_instances=1, max_instances=1, dataset_type=\"single_instance\")\n",
    "# extract_images([\"dog\"], min_instances=1, max_instances=1, dataset_type=\"single_instance\")\n",
    "# extract_images([\"chair\"], min_instances=1, max_instances=1, dataset_type=\"single_instance\")\n",
    "\n",
    "\n",
    "extract_images([\"cup\"], min_instances=1, dataset_type=\"single_instance\")\n",
    "extract_images([\"car\"], min_instances=1, dataset_type=\"single_instance\")\n",
    "extract_images([\"cat\"], min_instances=1, dataset_type=\"single_instance\")\n",
    "extract_images([\"dog\"], min_instances=1, dataset_type=\"single_instance\")\n",
    "extract_images([\"chair\"], min_instances=1, dataset_type=\"single_instance\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
